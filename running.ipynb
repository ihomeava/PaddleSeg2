{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.6/site-packages (21.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/opt/conda/bin/python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Model download success!\n"
     ]
    }
   ],
   "source": [
    "!python pretrained_model/download_model.py unet_bn_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: paddlepaddle-gpu in /opt/conda/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: gast>=0.3.3 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (0.4.0)\n",
      "Requirement already satisfied: astor in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (0.8.1)\n",
      "Requirement already satisfied: decorator==4.4.2 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (4.4.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (1.19.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (2.24.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (8.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.1.0->paddlepaddle-gpu) (49.2.0.post20200714)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \n",
      "PaddlePaddle works well on 1 GPU.\n",
      "PaddlePaddle works well on 1 GPUs.\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "paddle.utils.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5eabe37619c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#注意是双下划线\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)  #注意是双下划线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddleseg in /opt/conda/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.6/site-packages (from paddleseg) (3.4.1.15)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from paddleseg) (3.0.12)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/lib/python3.6/site-packages (from paddleseg) (2.13.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (5.3.1)\n",
      "Requirement already satisfied: yapf==0.26.0 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (0.26.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.6/site-packages (from paddleseg) (2.1.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from paddleseg) (1.5.0)\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from paddleseg) (4.31.1)\n",
      "Requirement already satisfied: flake8 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (3.7.9)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (3.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (1.19.1)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (1.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (2.24.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (0.8.60)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (8.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (3.13.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (0.7.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (0.24.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (1.15.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (2.0.0)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (2.5.0)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (2.1.1)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (0.6.1)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (0.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2020.1)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/lib/python3.6/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.11.0->visualdl>=2.0.0->paddleseg) (49.2.0.post20200714)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (0.18.2)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/lib/python3.6/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (3.10.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (1.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (5.1.4)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (1.6.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (20.4.7)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (0.10.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (2.2.10)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (3.3.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from virtualenv>=20.0.8->pre-commit->paddleseg) (0.3.2)\n",
      "Requirement already satisfied: appdirs<2,>=1.4.3 in /opt/conda/lib/python3.6/site-packages (from virtualenv>=20.0.8->pre-commit->paddleseg) (1.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->pre-commit->paddleseg) (3.1.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prettytable->paddleseg) (0.2.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->visualdl>=2.0.0->paddleseg) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->visualdl>=2.0.0->paddleseg) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->visualdl>=2.0.0->paddleseg) (2.9)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install paddleseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-07 13:09:44 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-5.4.0-89-generic-x86_64-with-debian-buster-sid\n",
      "Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "cudnn: 8.0\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: GeForce RTX', 'GPU 1: GeForce RTX']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PaddlePaddle: 2.1.3\n",
      "OpenCV: 4.4.0\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File configs/fastscnn_voc2012.yml does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         batch_size=args.batch_size)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/cvlibs/config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, learning_rate, batch_size, iters)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File {} does not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File configs/fastscnn_voc2012.yml does not exist"
     ]
    }
   ],
   "source": [
    "%run train.py --config configs/fastscnn_voc2012.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11355/11355 [00:00<00:00, 99082.99it/s]\n"
     ]
    }
   ],
   "source": [
    "%run tools/voc_augment.py --voc_path data/VOCdevkit --num_workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/src/app/local/liangyy/GitHub/PaddleSeg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export PYTHONPATH=`pwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-23 03:35:56 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-5.4.0-74-generic-x86_64-with-debian-buster-sid\n",
      "Python: 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "cudnn: 8.0\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: GeForce RTX', 'GPU 1: GeForce RTX']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 3.4.1\n",
      "------------------------------------------------\n",
      "2021-06-23 03:35:56 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 1000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: CrossEntropyLoss\n",
      "model:\n",
      "  pretrained: null\n",
      "  type: BiSeNetV2\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "val_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "------------------------------------------------\n",
      "W0623 03:35:56.659586  3972 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 10.2\n",
      "W0623 03:35:56.659607  3972 device_context.cc:422] device: 0, cuDNN Version: 8.0.\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 168, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 150, in main\n",
      "    cfg.model,\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/cvlibs/config.py\", line 256, in model\n",
      "    self._model = self._load_object(model_cfg)\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/cvlibs/config.py\", line 323, in _load_object\n",
      "    return component(**params)\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/bisenet.py\", line 54, in __init__\n",
      "    self.db = DetailBranch(db_channels)\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/bisenet.py\", line 192, in __init__\n",
      "    layers.ConvBNReLU(3, C1, 3, stride=2),\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/layers/layer_libs.py\", line 40, in __init__\n",
      "    in_channels, out_channels, kernel_size, padding=padding, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/nn/layer/conv.py\", line 646, in __init__\n",
      "    data_format=data_format)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/nn/layer/conv.py\", line 135, in __init__\n",
      "    default_initializer=_get_default_param_initializer())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 412, in create_parameter\n",
      "    default_initializer)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/layer_helper_base.py\", line 374, in create_parameter\n",
      "    **attr._to_kwargs(with_initializer=True))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 3193, in create_parameter\n",
      "    initializer(param, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/initializer.py\", line 364, in __call__\n",
      "    stop_gradient=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 3223, in append_op\n",
      "    kwargs.get(\"stop_gradient\", False))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py\", line 45, in trace_op\n",
      "    not stop_gradient)\n",
      "OSError: (External)  Cuda error(2), out of memory.\n",
      "  [Advise: The API call failed because it was unable to allocate enough memory to perform the requested operation. ] (at /paddle/paddle/fluid/platform/stream/cuda_stream.cc:49)\n",
      "  [operator < gaussian_random > error]\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1 # 设置1张可用的卡\n",
    "# windows下请执行以下命令\n",
    "# set CUDA_VISIBLE_DEVICES=0\n",
    "!python train.py \\\n",
    "       --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml \\\n",
    "       #--config configs/_base_/pascal_voc12aug.yml \\\n",
    "       #--config configs/pascal/fastscnn_pascal_voc12.yml \\\n",
    "       --do_eval \\\n",
    "       --use_vdl \\\n",
    "       --save_interval 500 \\\n",
    "       --save_dir output\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 python train.py --config configs/pascal/fastscnn_pascal_voc12.yml --do_eval --use_vdl --save_interval 500 --save_dir output  --resume_model output/iter_14000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (119974720.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_24577/119974720.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    CUDA_VISIBLE_DEVICES=0,1 python train.py --config configs/unet/unet_cityscapes_1024x512_160k-2.yml --do_eval --use_vdl --save_interval 500 --save_dir output\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#CUDA_VISIBLE_DEVICES=0,1 python train.py --config configs/pascal/fastscnn_pascal_voc12.yml --do_eval --use_vdl --save_interval 500 --save_dir output  --resume_model output/iter_14000\n",
    "export CUDA_VISIBLE_DEVICES=0,1\n",
    "python -m paddle.distributed.launch train.py --config configs/unet/unet_cityscapes_1024x512_160k-2.yml --do_eval --use_vdl --save_interval 500 --save_dir output\n",
    "python -m paddle.distributed.launch train.py --config configs/unet_plusplus/unet_plusplus_cityscapes_1024x512_160k-2.yml --do_eval --use_vdl --save_interval 500 --save_dir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载并解压数据集\n",
    "! mkdir dataset\n",
    "%cd dataset\n",
    "! wget https://paddleseg.bj.bcebos.com/dataset/optic_disc_seg.zip\n",
    "! unzip optic_disc_seg.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 08 00:09:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 36%   39C    P8    21W / 370W |    644MiB / 24576MiB |     10%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1456    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1676    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      2756    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2956    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A      8156    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10272    C+G   ...ta\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     16992    C+G   Insufficient Permissions        N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 11:48:26 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 2\n",
      "iters: 160000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "model:\n",
      "  num_classes: 19\n",
      "  pretrained: null\n",
      "  type: UNet\n",
      "  use_deconv: false\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 1024\n",
      "    - 512\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "val_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 11:48:26.764458 24577 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1028 11:48:26.764473 24577 device_context.cc:422] device: 0, cuDNN Version: 8.0.\n",
      "W1028 11:48:28.866786 24577 device_context.h:361] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.1, but CUDNN version in your machine is 8.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 11:48:30 [INFO]\tNumber of predict images = 181\n",
      "2021-10-28 11:48:30 [INFO]\tLoading pretrained model from output/iter_19500/model.pdparams\n",
      "2021-10-28 11:48:31 [INFO]\tThere are 112/112 variables loaded into UNet.\n",
      "2021-10-28 11:48:31 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Operator conv2d raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 512.000244MB memory on GPU 0, 10.504517GB memory has been allocated and available memory is only 259.687500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/predict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/predict.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mis_slide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_slide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/core/predict.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, model_path, transforms, image_list, image_dir, save_dir, aug_pred, scales, flip_horizontal, flip_vertical, is_slide, stride, crop_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mis_slide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_slide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     crop_size=crop_size)\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/core/infer.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, im, ori_shape, transforms, is_slide, stride, crop_size)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_slide\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlogit_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_cuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_cuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mshort_cuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdown_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_sample_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mshort_cuts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/layers/layer_libs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/nn/layer/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mchannel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_channel_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mop_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             use_cudnn=self._use_cudnn)\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/nn/functional/conv.py\u001b[0m in \u001b[0;36m_conv_nd\u001b[0;34m(x, weight, bias, stride, padding, padding_algorithm, dilation, groups, data_format, channel_dim, op_type, use_cudnn, use_mkldnn, name)\u001b[0m\n\u001b[1;32m    112\u001b[0m                  \u001b[0;34m\"padding_algorithm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_algorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                  data_format)\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mpre_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementwise_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Operator conv2d raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 512.000244MB memory on GPU 0, 10.504517GB memory has been allocated and available memory is only 259.687500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n"
     ]
    }
   ],
   "source": [
    "export CUDA_VISIBLE_DEVICES=1\n",
    "python predict.py --config configs/unet/unet_cityscapes_1024x512_160k-2.yml --model_path output/iter_19500/model.pdparams --image_path data/cityscapes/leftImg8bit/test/bielefeld --save_dir output/result\n",
    "python predict.py --config configs/unet_plusplus/unet_plusplus_cityscapes_1024x512_160k-2.yml --model_path output/iter_19500/model.pdparams --image_path data/cityscapes/leftImg8bit/test/bielefeld --save_dir output/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-20 17:22:29 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 160000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "model:\n",
      "  num_classes: 19\n",
      "  pretrained: null\n",
      "  type: UNet\n",
      "  use_deconv: false\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 1024\n",
      "    - 512\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "val_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "------------------------------------------------\n",
      "2021-11-20 17:22:32 [INFO]\tNumber of predict images = 500\n",
      "2021-11-20 17:22:32 [INFO]\tLoading pretrained model from output/iter_2000/model.pdparams\n",
      "2021-11-20 17:22:32 [INFO]\tThere are 112/112 variables loaded into UNet.\n",
      "2021-11-20 17:22:32 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 14s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "#%run deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/bisenetv2_demo_model/deploy.yaml --image_path data/test_list2.txt --batch_size 1 --save_dir output/result\n",
    "#%run deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/attention_unet_vocleather_512x512_280/deploy.yaml --image_path data/test_list1.txt --batch_size 56 --save_dir output/result\n",
    "%run deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/attention_unet_vocleather_512x512_280/deploy.yaml --image_path data/vocleather/Image_20211105145758314.bmp --save_dir output/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33ab0e4-10f9-4c6b-a299-bd929a382956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-23 23:54:18 [INFO]\tUse CPU\n",
      "2021-11-23 23:54:24 [INFO]\tFinish\n"
     ]
    }
   ],
   "source": [
    "#%run tools/split_dataset_list.py data/optic_disc_seg JPEGImages Annotations --split 0.8 0.1 0.1 --format jpg png\n",
    "#%run tools/labelme2seg.py data/optic_disc_seg/JPEGImages\n",
    "\n",
    "#python train.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --do_eval --use_vdl --save_interval 500 --save_dir output/bisenet_optic_disc_512x512_1k --resume_model output/bisenet_optic_disc_512x512_1k/iter_500\n",
    "#python train.py --config configs/attention_unet/attention_unet_optic_disc_512x512_1k.yml --do_eval --use_vdl --save_interval 500 --save_dir output/attention_unet_optic_disc_512x512_1k --resume_model output/attention_unet_optic_disc_512x512_1k/iter_1000\n",
    "\n",
    "#visualdl --logdir output/bisenet_optic_disc_512x512_1k/\n",
    "#visualdl --logdir D:\\Deep_Learning\\liangyy\\PaddleSeg\\output/attention_unet_optic_disc_512x512_1k\n",
    "\n",
    "#python val.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path output/bisenet_optic_disc_512x512_1k/iter_10000/model.pdparams\n",
    "\n",
    "#%run predict.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path output/bisenet_optic_disc_512x512_1k/best_model/model.pdparams --image_path data/optic_disc_seg/test --save_dir output/bisenet_optic_disc_512x512_1k/result\n",
    "#%run predict.py --config configs/attention_unet/attention_unet_optic_disc_512x512_1k.yml --model_path output/attention_unet_optic_disc_512x512_1k/best_model/model.pdparams --image_path data/optic_disc_seg/test --save_dir output/attention_unet_optic_disc_512x512_1k/result\n",
    "\n",
    "#%run export.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path output/bisenet_optic_disc_512x512_1k/iter_10000/model.pdparams --save_dir output/bisenet_optic_disc_512x512_1k\n",
    "#%run export.py --config configs/attention_unet/attention_unet_optic_disc_512x512_1k.yml --model_path output/attention_unet_optic_disc_512x512_1k/best_model/model.pdparams --save_dir output/attention_unet_optic_disc_512x512_1k/deploy\n",
    "\n",
    "%run deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/attention_unet_optic_disc_512x512_1k/deploy/deploy.yaml --image_path data/optic_disc_seg/test/N0031.jpg --save_dir output/attention_unet_optic_disc_512x512_1k/result\n",
    "#%run deploy/python/infer.py --device gpu --config output/attention_unet_optic_disc_512x512_1k/deploy/deploy.yaml --image_path data/optic_disc_seg/test --save_dir output/attention_unet_optic_disc_512x512_1k/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-25 21:28:28 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Windows-10-10.0.17763-SP0\n",
      "Python: 3.6.13 (default, Sep 23 2021, 07:38:49) [MSC v.1916 64 bit (AMD64)]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Not Available\n",
      "cudnn: 8.1\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: GeForce RTX']\n",
      "PaddlePaddle: 2.2.0\n",
      "OpenCV: 4.4.0\n",
      "------------------------------------------------\n",
      "2021-11-25 21:28:28 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 160000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: CrossEntropyLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  num_classes: 19\n",
      "  pretrained: null\n",
      "  type: UNet\n",
      "  use_deconv: false\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 1024\n",
      "    - 512\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "val_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\host\\Miniconda3\\envs\\paddlepaddle\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:653: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "C:\\Users\\host\\Miniconda3\\envs\\paddlepaddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\math_op_patch.py:253: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.int64, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Deep_Learning\\liangyy\\PaddleSeg\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Deep_Learning\\liangyy\\PaddleSeg\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mtest_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mfp16\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         profiler_options=args.profiler_options)\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Deep_Learning\\liangyy\\PaddleSeg\\paddleseg\\core\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, val_dataset, optimizer, save_dir, iters, batch_size, resume_model, save_interval, log_iters, num_workers, use_vdl, losses, keep_checkpoint_max, test_config, fp16, profiler_options)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mavg_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mavg_loss_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                 \u001b[0mavg_loss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train.py --config configs/unet/unet_cityscapes_1024x512_160k.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating traing05.txt...\n",
      "Creating val05.txt...\n",
      "Creating test05.txt...\n"
     ]
    }
   ],
   "source": [
    "#d:\n",
    "#cd Deep_Learning\\liangyy\\PaddleSeg\n",
    "#conda activate paddlepaddle\n",
    "\n",
    "%run tools/split_dataset_list.py data/voc/VOCdevkit/VOCleather JPEGImages05 SegmentationClass05 --split 0.8 0.1 0.1 --format bmp png\n",
    "\n",
    "#%run tools/labelme2seg.py data/voc/VOCdevkit/VOCleather/JPEGImages05\n",
    "\n",
    "#python train.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --do_eval --use_vdl --save_interval 500 --save_dir output/unet_pascalvoc_1024x512_160k --resume_model output/unet_pascalvoc_1024x512_160k/iter_500\n",
    "#python train.py --config configs/unet/unet_vocleather_512x512_280.yml --do_eval --use_vdl --save_interval 500 --save_dir output/unet_vocleather_512x512_280 --resume_model output/unet_vocleather_512x512_280/iter_500\n",
    "#python train.py --config configs/attention_unet/attention_unet_vocleather_512x512_280.yml --do_eval --use_vdl --save_interval 50 --save_dir output/attention_unet_vocleather_512x512_280_202111271000 --resume_model output/attention_unet_vocleather_512x512_280_202111271000/iter_50\n",
    "#python train.py --config configs/unet_3plus/unet_3plus_vocleather_512x512_280.yml --do_eval --use_vdl --save_interval 500 --save_dir output/unet_3plus_vocleather_512x512_280_202111232208 --resume_model output/unet_3plus_vocleather_512x512_280_202111232208/iter_50\n",
    "\n",
    "#visualdl --port 8040 --logdir output/unet_pascalvoc_1024x512_160k/\n",
    "#visualdl --port 8040 --logdir D:\\Deep_Learning\\liangyy\\PaddleSeg\\output\\attention_unet_vocleather_512x512_280_202111261612\n",
    "\n",
    "#python val.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --model_path output/unet_pascalvoc_1024x512_160k/iter_1500/model.pdparams\n",
    "\n",
    "#%run predict.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --model_path output/unet_pascalvoc_1024x512_160k/iter_2000/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test --save_dir output/unet_pascalvoc_1024x512_160k/result\n",
    "#%run predict.py --config configs/unet/unet_vocleather_512x512_280.yml --model_path output/unet_vocleather_512x512_280/iter_300/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test --save_dir output/unet_vocleather_512x512_280/result\n",
    "#%run predict.py --config configs/attention_unet/attention_unet_vocleather_512x512_280.yml --model_path output/attention_unet_vocleather_512x512_280_202111261612/best_model/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test05 --save_dir output/attention_unet_vocleather_512x512_280_202111261612/result\n",
    "#%run predict.py --config configs/unet_3plus/unet_3plus_vocleather_512x512_280.yml --model_path output/unet_3plus_vocleather_512x512_280_202111232208/best_model/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test05 --save_dir output/unet_3plus_vocleather_512x512_280_202111232208/result\n",
    "\n",
    "#%run export.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --model_path output/unet_pascalvoc_1024x512_160k/iter_10000/model.pdparams --save_dir output/unet_pascalvoc_1024x512_160k\n",
    "#%run export.py --config configs/attention_unet/attention_unet_vocleather_512x512_280.yml --model_path output/attention_unet_vocleather_512x512_280_202111252307/best_model/model.pdparams --save_dir output/attention_unet_vocleather_512x512_280_202111252307/deploy\n",
    "#%run export.py --config configs/unet_3plus/unet_3plus_vocleather_512x512_280.yml --model_path output/unet_3plus_vocleather_512x512_280_202111232208/best_model/model.pdparams --save_dir output/unet_3plus_vocleather_512x512_280_202111232208/deploy\n",
    "\n",
    "#python deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/attention_unet_vocleather_512x512_280/deploy.yaml --image_path data/voc/VOCdevkit/VOCleather/test/Image_20211105141003930.bmp --save_dir output/attention_unet_vocleather_512x512_280\n",
    "#python deploy/python/infer.py --config output/attention_unet_vocleather_512x512_280_202111252307/deploy/deploy.yaml --image_path data/voc/VOCdevkit/VOCleather/JPEGImages021/Image_20211105141003930.bmp --save_dir output/attention_unet_vocleather_512x512_280_202111252307/result2\n",
    "#python deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/deploy.yaml --image_path data/voc/VOCdevkit/VOCleather/test/Image_20211105141003930.bmp --save_dir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件名为:  D:\\Deep_Learning\\liangyy\\data\\voc\\VOCdevkit\\VOCleather\\test05.txt\n",
      "读取的数据为: Image_20211105140906414.bmp\n",
      "读取的数据为: Image_20211105135847035.bmp\n",
      "读取的数据为: Image_20211105145845976.bmp\n",
      "读取的数据为: Image_20211105150255722.bmp\n",
      "读取的数据为: Image_20211105135929418.bmp\n",
      "读取的数据为: Image_20211105134009255.bmp\n",
      "读取的数据为: Image_20211105152353177.bmp\n",
      "读取的数据为: Image_20211105144812844.bmp\n",
      "读取的数据为: Image_20211105141617308.bmp\n",
      "读取的数据为: Image_20211105141928613.bmp\n",
      "读取的数据为: Image_20211105150114060.bmp\n",
      "读取的数据为: Image_20211105134912067.bmp\n",
      "读取的数据为: Image_20211105111231523.bmp\n",
      "读取的数据为: Image_20211105145758314.bmp\n",
      "读取的数据为: Image_20211105152152318.bmp\n",
      "读取的数据为: 烂点027.bmp\n",
      "读取的数据为: Image_20211105133609279.bmp\n",
      "读取的数据为: 压印001.bmp\n",
      "读取的数据为: 疤点001.bmp\n",
      "读取的数据为: 烂点005.bmp\n",
      "读取的数据为: Image_20211105150847367.bmp\n",
      "读取的数据为: Image_20211105135027950.bmp\n",
      "读取的数据为: Image_20211105151648666.bmp\n",
      "读取的数据为: Image_20211105152123794.bmp\n",
      "读取的数据为: Image_20211105141756642.bmp\n",
      "读取的数据为: 烂点028.bmp\n",
      "读取的数据为: Image_20211105150636922.bmp\n",
      "读取的数据为: 折痕017.bmp\n",
      "读取的数据为: Image_20211105144340220.bmp\n",
      "读取的数据为: Image_20211105141354512.bmp\n",
      "读取的数据为: Image_20211105151635415.bmp\n",
      "读取的数据为: Image_20211105150044863.bmp\n",
      "读取的数据为: 烂点002.bmp\n",
      "读取的数据为: Image_20211105135946422.bmp\n",
      "读取的数据为: Image_20211105134031431.bmp\n",
      "读取的数据为: Image_20211105141857326.bmp\n",
      "读取的数据为: Image_20211105142046716.bmp\n",
      "读取的数据为: Image_20211105145056928.bmp\n",
      "读取的数据为: Image_20211105144422060.bmp\n",
      "读取的数据为: 牙签013.bmp\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "import os\n",
    "\n",
    "pwd = 'D:\\\\Deep_Learning\\\\liangyy\\\\data\\\\voc\\\\VOCdevkit\\\\VOCleather'          #<--------------------------------\n",
    "# 打开文件\n",
    "fo = open(pwd+\"\\\\\"+\"test05.txt\", \"r\", encoding='gbk')                         #<--------------------------------\n",
    "print(\"文件名为: \", fo.name)\n",
    " \n",
    "for line in fo.readlines():                          #依次读取每行  \n",
    "    line = line.strip().split()[0].split('\\\\')[1]    #去掉每行头尾空白         #<--------------------------------\n",
    "    print(\"读取的数据为: %s\" % line)\n",
    "    \n",
    "    os.system('copy %s\\\\JPEGImages05\\\\%s %s\\\\test05\\\\%s' % (pwd,line,pwd,line)) #<--------------------------------\n",
    " \n",
    "# 关闭文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "trainval_percent = 0.9\n",
    "train_percent = 0.9\n",
    "xmlfilepath = '../SegmentationClass02'#<--------------------------\n",
    "txtsavepath = '../ImageSets/Main'\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    "\n",
    "num = len(total_xml)\n",
    "list = range(num)\n",
    "tv = int(num*trainval_percent)\n",
    "tr = int(tv*train_percent)\n",
    "trainval = random.sample(list, tv)\n",
    "train = random.sample(trainval, tr)\n",
    "\n",
    "ftrainval = open('../ImageSets/Main/trainval.txt', 'w', encoding='utf-8')\n",
    "ftest = open('../ImageSets/Main/test.txt', 'w', encoding='utf-8')\n",
    "ftrain = open('../ImageSets/Main/train.txt', 'w', encoding='utf-8')\n",
    "fval = open('../ImageSets/Main/val.txt', 'w', encoding='utf-8')\n",
    "\n",
    "for i in list:\n",
    "    name = total_xml[i][:-4]+'\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    "\n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest .close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "sets = [('', 'train'), ('', 'val'), ('', 'test')]\n",
    "\n",
    "wd = '.'\n",
    "\n",
    "for year, image_set in sets:\n",
    "    image_ids = open('../ImageSets/Main/%s.txt' % image_set, encoding='utf-8').read().strip().split()\n",
    "    list_file = open('../%s.txt' % image_set, 'w', encoding='utf-8')\n",
    "    for image_id in image_ids:\n",
    "        #list_file.write('%s/JPEGImages01/%s.%s\\n' % (wd, image_id, 'bmp'))#<--------------------------\n",
    "        list_file.write('%s/JPEGImages02/%s.%s %s/SegmentationClass02/%s.%s\\n' % (wd, image_id, 'bmp', wd, image_id, 'png'))#<--------------------------\n",
    "    list_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取目录下所有图片,更改尺寸后保存到另一目录\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "def convertjpg(jpgfile,outdir,width=512,height=512):\n",
    "    img=Image.open(jpgfile)\n",
    "    try:\n",
    "        new_img=img.resize((width,height),Image.BILINEAR)   \n",
    "        new_img.save(os.path.join(outdir,os.path.basename(jpgfile)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "for jpgfile in glob.glob(\"D:\\\\Deep_Learning\\\\liangyy\\\\data\\\\voc\\\\VOCdevkit\\\\VOCleather\\\\JPEGImages02\\\\*.bmp\"):\n",
    "    convertjpg(jpgfile,\"D:\\\\Deep_Learning\\\\liangyy\\\\data\\\\voc\\\\VOCdevkit\\\\VOCleather\\\\JPEGImages021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14e739-c55a-4107-9d1c-4a48c27acd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddlepaddle",
   "language": "python",
   "name": "paddlepaddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
