{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.6/site-packages (21.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/opt/conda/bin/python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Model download success!\n"
     ]
    }
   ],
   "source": [
    "!python pretrained_model/download_model.py unet_bn_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: paddlepaddle-gpu in /opt/conda/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: gast>=0.3.3 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (0.4.0)\n",
      "Requirement already satisfied: astor in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (0.8.1)\n",
      "Requirement already satisfied: decorator==4.4.2 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (4.4.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (1.19.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (2.24.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from paddlepaddle-gpu) (8.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.1.0->paddlepaddle-gpu) (49.2.0.post20200714)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \n",
      "PaddlePaddle works well on 1 GPU.\n",
      "PaddlePaddle works well on 1 GPUs.\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "paddle.utils.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5eabe37619c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#注意是双下划线\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)  #注意是双下划线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddleseg in /opt/conda/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.6/site-packages (from paddleseg) (3.4.1.15)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from paddleseg) (3.0.12)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/lib/python3.6/site-packages (from paddleseg) (2.13.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (5.3.1)\n",
      "Requirement already satisfied: yapf==0.26.0 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (0.26.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.6/site-packages (from paddleseg) (2.1.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from paddleseg) (1.5.0)\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from paddleseg) (4.31.1)\n",
      "Requirement already satisfied: flake8 in /opt/conda/lib/python3.6/site-packages (from paddleseg) (3.7.9)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (3.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (1.19.1)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (1.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (2.24.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (0.8.60)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (8.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (3.13.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (0.7.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (0.24.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (1.15.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from visualdl>=2.0.0->paddleseg) (2.0.0)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (2.5.0)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (2.1.1)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (0.6.1)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from flake8->paddleseg) (0.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.6/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2020.1)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/lib/python3.6/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.11.0->visualdl>=2.0.0->paddleseg) (49.2.0.post20200714)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (0.18.2)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/lib/python3.6/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (3.10.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (1.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (5.1.4)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (1.6.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (20.4.7)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (0.10.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (2.2.10)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from pre-commit->paddleseg) (3.3.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from virtualenv>=20.0.8->pre-commit->paddleseg) (0.3.2)\n",
      "Requirement already satisfied: appdirs<2,>=1.4.3 in /opt/conda/lib/python3.6/site-packages (from virtualenv>=20.0.8->pre-commit->paddleseg) (1.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->pre-commit->paddleseg) (3.1.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prettytable->paddleseg) (0.2.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->visualdl>=2.0.0->paddleseg) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->visualdl>=2.0.0->paddleseg) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->visualdl>=2.0.0->paddleseg) (2.9)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install paddleseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-07 13:09:44 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-5.4.0-89-generic-x86_64-with-debian-buster-sid\n",
      "Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "cudnn: 8.0\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: GeForce RTX', 'GPU 1: GeForce RTX']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PaddlePaddle: 2.1.3\n",
      "OpenCV: 4.4.0\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File configs/fastscnn_voc2012.yml does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         batch_size=args.batch_size)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/cvlibs/config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, learning_rate, batch_size, iters)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File {} does not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File configs/fastscnn_voc2012.yml does not exist"
     ]
    }
   ],
   "source": [
    "%run train.py --config configs/fastscnn_voc2012.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11355/11355 [00:00<00:00, 99082.99it/s]\n"
     ]
    }
   ],
   "source": [
    "%run tools/voc_augment.py --voc_path data/VOCdevkit --num_workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/src/app/local/liangyy/GitHub/PaddleSeg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export PYTHONPATH=`pwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-23 03:35:56 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-5.4.0-74-generic-x86_64-with-debian-buster-sid\n",
      "Python: 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Build cuda_11.0_bu.TC445_37.28845127_0\n",
      "cudnn: 8.0\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: GeForce RTX', 'GPU 1: GeForce RTX']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 3.4.1\n",
      "------------------------------------------------\n",
      "2021-06-23 03:35:56 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 1000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: CrossEntropyLoss\n",
      "model:\n",
      "  pretrained: null\n",
      "  type: BiSeNetV2\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "val_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "------------------------------------------------\n",
      "W0623 03:35:56.659586  3972 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 10.2\n",
      "W0623 03:35:56.659607  3972 device_context.cc:422] device: 0, cuDNN Version: 8.0.\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 168, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 150, in main\n",
      "    cfg.model,\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/cvlibs/config.py\", line 256, in model\n",
      "    self._model = self._load_object(model_cfg)\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/cvlibs/config.py\", line 323, in _load_object\n",
      "    return component(**params)\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/bisenet.py\", line 54, in __init__\n",
      "    self.db = DetailBranch(db_channels)\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/bisenet.py\", line 192, in __init__\n",
      "    layers.ConvBNReLU(3, C1, 3, stride=2),\n",
      "  File \"/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/layers/layer_libs.py\", line 40, in __init__\n",
      "    in_channels, out_channels, kernel_size, padding=padding, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/nn/layer/conv.py\", line 646, in __init__\n",
      "    data_format=data_format)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/nn/layer/conv.py\", line 135, in __init__\n",
      "    default_initializer=_get_default_param_initializer())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\", line 412, in create_parameter\n",
      "    default_initializer)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/layer_helper_base.py\", line 374, in create_parameter\n",
      "    **attr._to_kwargs(with_initializer=True))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 3193, in create_parameter\n",
      "    initializer(param, self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/initializer.py\", line 364, in __call__\n",
      "    stop_gradient=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 3223, in append_op\n",
      "    kwargs.get(\"stop_gradient\", False))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py\", line 45, in trace_op\n",
      "    not stop_gradient)\n",
      "OSError: (External)  Cuda error(2), out of memory.\n",
      "  [Advise: The API call failed because it was unable to allocate enough memory to perform the requested operation. ] (at /paddle/paddle/fluid/platform/stream/cuda_stream.cc:49)\n",
      "  [operator < gaussian_random > error]\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1 # 设置1张可用的卡\n",
    "# windows下请执行以下命令\n",
    "# set CUDA_VISIBLE_DEVICES=0\n",
    "!python train.py \\\n",
    "       --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml \\\n",
    "       #--config configs/_base_/pascal_voc12aug.yml \\\n",
    "       #--config configs/pascal/fastscnn_pascal_voc12.yml \\\n",
    "       --do_eval \\\n",
    "       --use_vdl \\\n",
    "       --save_interval 500 \\\n",
    "       --save_dir output\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 python train.py --config configs/pascal/fastscnn_pascal_voc12.yml --do_eval --use_vdl --save_interval 500 --save_dir output  --resume_model output/iter_14000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (119974720.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_24577/119974720.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    CUDA_VISIBLE_DEVICES=0,1 python train.py --config configs/unet/unet_cityscapes_1024x512_160k-2.yml --do_eval --use_vdl --save_interval 500 --save_dir output\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#CUDA_VISIBLE_DEVICES=0,1 python train.py --config configs/pascal/fastscnn_pascal_voc12.yml --do_eval --use_vdl --save_interval 500 --save_dir output  --resume_model output/iter_14000\n",
    "export CUDA_VISIBLE_DEVICES=0,1\n",
    "python -m paddle.distributed.launch train.py --config configs/unet/unet_cityscapes_1024x512_160k-2.yml --do_eval --use_vdl --save_interval 500 --save_dir output\n",
    "python -m paddle.distributed.launch train.py --config configs/unet_plusplus/unet_plusplus_cityscapes_1024x512_160k-2.yml --do_eval --use_vdl --save_interval 500 --save_dir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载并解压数据集\n",
    "! mkdir dataset\n",
    "%cd dataset\n",
    "! wget https://paddleseg.bj.bcebos.com/dataset/optic_disc_seg.zip\n",
    "! unzip optic_disc_seg.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 08 00:09:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 36%   39C    P8    21W / 370W |    644MiB / 24576MiB |     10%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1456    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1676    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      2756    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2956    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A      8156    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10272    C+G   ...ta\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     16992    C+G   Insufficient Permissions        N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 11:48:26 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 2\n",
      "iters: 160000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "model:\n",
      "  num_classes: 19\n",
      "  pretrained: null\n",
      "  type: UNet\n",
      "  use_deconv: false\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 1024\n",
      "    - 512\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "val_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 11:48:26.764458 24577 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1028 11:48:26.764473 24577 device_context.cc:422] device: 0, cuDNN Version: 8.0.\n",
      "W1028 11:48:28.866786 24577 device_context.h:361] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.1, but CUDNN version in your machine is 8.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 11:48:30 [INFO]\tNumber of predict images = 181\n",
      "2021-10-28 11:48:30 [INFO]\tLoading pretrained model from output/iter_19500/model.pdparams\n",
      "2021-10-28 11:48:31 [INFO]\tThere are 112/112 variables loaded into UNet.\n",
      "2021-10-28 11:48:31 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Operator conv2d raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 512.000244MB memory on GPU 0, 10.504517GB memory has been allocated and available memory is only 259.687500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/predict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/predict.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mis_slide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_slide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/core/predict.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, model_path, transforms, image_list, image_dir, save_dir, aug_pred, scales, flip_horizontal, flip_vertical, is_slide, stride, crop_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mis_slide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_slide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     crop_size=crop_size)\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/core/infer.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, im, ori_shape, transforms, is_slide, stride, crop_size)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_slide\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlogit_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_cuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_cuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mshort_cuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdown_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_sample_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mshort_cuts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/local/liangyy/GitHub/PaddleSeg/paddleseg/models/layers/layer_libs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/nn/layer/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mchannel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_channel_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mop_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             use_cudnn=self._use_cudnn)\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/paddle/lib/python3.7/site-packages/paddle/nn/functional/conv.py\u001b[0m in \u001b[0;36m_conv_nd\u001b[0;34m(x, weight, bias, stride, padding, padding_algorithm, dilation, groups, data_format, channel_dim, op_type, use_cudnn, use_mkldnn, name)\u001b[0m\n\u001b[1;32m    112\u001b[0m                  \u001b[0;34m\"padding_algorithm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_algorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                  data_format)\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mpre_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementwise_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Operator conv2d raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 512.000244MB memory on GPU 0, 10.504517GB memory has been allocated and available memory is only 259.687500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n"
     ]
    }
   ],
   "source": [
    "export CUDA_VISIBLE_DEVICES=1\n",
    "python predict.py --config configs/unet/unet_cityscapes_1024x512_160k-2.yml --model_path output/iter_19500/model.pdparams --image_path data/cityscapes/leftImg8bit/test/bielefeld --save_dir output/result\n",
    "python predict.py --config configs/unet_plusplus/unet_plusplus_cityscapes_1024x512_160k-2.yml --model_path output/iter_19500/model.pdparams --image_path data/cityscapes/leftImg8bit/test/bielefeld --save_dir output/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-20 17:22:29 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 160000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "model:\n",
      "  num_classes: 19\n",
      "  pretrained: null\n",
      "  type: UNet\n",
      "  use_deconv: false\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 1024\n",
      "    - 512\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "val_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "------------------------------------------------\n",
      "2021-11-20 17:22:32 [INFO]\tNumber of predict images = 500\n",
      "2021-11-20 17:22:32 [INFO]\tLoading pretrained model from output/iter_2000/model.pdparams\n",
      "2021-11-20 17:22:32 [INFO]\tThere are 112/112 variables loaded into UNet.\n",
      "2021-11-20 17:22:32 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 14s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "%run predict.py --config configs/unet/unet_cityscapes_1024x512_160k.yml --model_path output/iter_2000/model.pdparams --image_path data/cityscapes/testA  --save_dir output/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-23 14:41:49 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 10000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  pretrained: null\n",
      "  type: AttentionUNet\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "val_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "------------------------------------------------\n",
      "2021-11-23 14:41:49 [INFO]\tNumber of predict images = 38\n",
      "2021-11-23 14:41:49 [INFO]\tLoading pretrained model from output_attention_unet_optic_disc_512x512_1k/best_model/model.pdparams\n",
      "2021-11-23 14:41:51 [INFO]\tThere are 206/206 variables loaded into AttentionUNet.\n",
      "2021-11-23 14:41:51 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 141ms/step\n"
     ]
    }
   ],
   "source": [
    "#%run tools/split_dataset_list.py data/optic_disc_seg JPEGImages Annotations --split 0.8 0.1 0.1 --format jpg png\n",
    "#%run tools/labelme2seg.py data/optic_disc_seg/JPEGImages\n",
    "\n",
    "#python train.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --do_eval --use_vdl --save_interval 500 --save_dir output_bisenet_optic_disc_512x512_1k --resume_model output_bisenet_optic_disc_512x512_1k/iter_500\n",
    "#python train.py --config configs/attention_unet/attention_unet_optic_disc_512x512_1k.yml --do_eval --use_vdl --save_interval 500 --save_dir output_attention_unet_optic_disc_512x512_1k --resume_model output_attention_unet_optic_disc_512x512_1k/iter_1000\n",
    "\n",
    "#visualdl --logdir output_bisenet_optic_disc_512x512_1k/\n",
    "#visualdl --logdir D:\\Deep_Learning\\liangyy\\PaddleSeg\\output_attention_unet_optic_disc_512x512_1k\n",
    "\n",
    "#python val.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path output_bisenet_optic_disc_512x512_1k/iter_10000/model.pdparams\n",
    "\n",
    "#%run predict.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path output_bisenet_optic_disc_512x512_1k/best_model/model.pdparams --image_path data/optic_disc_seg/test --save_dir output_bisenet_optic_disc_512x512_1k/result\n",
    "%run predict.py --config configs/attention_unet/attention_unet_optic_disc_512x512_1k.yml --model_path output_attention_unet_optic_disc_512x512_1k/best_model/model.pdparams --image_path data/optic_disc_seg/test --save_dir output_attention_unet_optic_disc_512x512_1k/result\n",
    "\n",
    "#python export.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path output_bisenet_optic_disc_512x512_1k/iter_10000/model.pdparams --save_dir output_bisenet_optic_disc_512x512_1k\n",
    "#%run export.py --config configs/attention_unet/attention_unet_optic_disc_512x512_1k.yml --model_path output_attention_unet_optic_disc_512x512_1k/best_model/model.pdparams --save_dir output_attention_unet_optic_disc_512x512_1k/deploy\n",
    "\n",
    "#%run deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output_attention_unet_optic_disc_512x512_1k/deploy/deploy.yaml --image_path data/optic_disc_seg/test/N0031.jpg --save_dir output_attention_unet_optic_disc_512x512_1k/result\n",
    "#%run deploy/python/infer.py --device gpu --config output_attention_unet_optic_disc_512x512_1k/deploy/deploy.yaml --image_path data/optic_disc_seg/test --save_dir output_attention_unet_optic_disc_512x512_1k/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-19 23:33:08 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Windows-10-10.0.17763-SP0\n",
      "Python: 3.6.13 (default, Sep 23 2021, 07:38:49) [MSC v.1916 64 bit (AMD64)]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Not Available\n",
      "cudnn: 8.1\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: GeForce RTX']\n",
      "PaddlePaddle: 2.2.0\n",
      "OpenCV: 4.4.0\n",
      "------------------------------------------------\n",
      "2021-11-19 23:33:08 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 160000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: CrossEntropyLoss\n",
      "model:\n",
      "  num_classes: 19\n",
      "  pretrained: null\n",
      "  type: UNet\n",
      "  use_deconv: false\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 1024\n",
      "    - 512\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "val_dataset:\n",
      "  dataset_root: data/cityscapes\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Cityscapes\n",
      "------------------------------------------------\n",
      "2021-11-19 23:33:19 [INFO]\t[TRAIN] epoch=1, iter=10/160000, loss=2.3902, lr=0.009999, batch_cost=0.8014, reader_cost=0.05824, ips=4.9915 samples/sec | ETA 35:36:49\n",
      "2021-11-19 23:33:27 [INFO]\t[TRAIN] epoch=1, iter=20/160000, loss=1.8239, lr=0.009999, batch_cost=0.7973, reader_cost=0.18501, ips=5.0171 samples/sec | ETA 35:25:46\n",
      "2021-11-19 23:33:35 [INFO]\t[TRAIN] epoch=1, iter=30/160000, loss=1.7428, lr=0.009998, batch_cost=0.7952, reader_cost=0.18112, ips=5.0303 samples/sec | ETA 35:20:03\n",
      "2021-11-19 23:33:43 [INFO]\t[TRAIN] epoch=1, iter=40/160000, loss=1.5773, lr=0.009998, batch_cost=0.7843, reader_cost=0.17274, ips=5.1001 samples/sec | ETA 34:50:57\n",
      "2021-11-19 23:33:51 [INFO]\t[TRAIN] epoch=1, iter=50/160000, loss=1.6464, lr=0.009997, batch_cost=0.8048, reader_cost=0.18929, ips=4.9699 samples/sec | ETA 35:45:35\n",
      "2021-11-19 23:33:59 [INFO]\t[TRAIN] epoch=1, iter=60/160000, loss=1.5434, lr=0.009997, batch_cost=0.7988, reader_cost=0.18381, ips=5.0077 samples/sec | ETA 35:29:14\n",
      "2021-11-19 23:34:07 [INFO]\t[TRAIN] epoch=1, iter=70/160000, loss=1.4645, lr=0.009996, batch_cost=0.7850, reader_cost=0.16466, ips=5.0955 samples/sec | ETA 34:52:25\n",
      "2021-11-19 23:34:15 [INFO]\t[TRAIN] epoch=1, iter=80/160000, loss=1.5949, lr=0.009996, batch_cost=0.8127, reader_cost=0.19408, ips=4.9217 samples/sec | ETA 36:06:11\n",
      "2021-11-19 23:34:23 [INFO]\t[TRAIN] epoch=1, iter=90/160000, loss=1.5486, lr=0.009995, batch_cost=0.8167, reader_cost=0.19438, ips=4.8977 samples/sec | ETA 36:16:41\n",
      "2021-11-19 23:34:32 [INFO]\t[TRAIN] epoch=1, iter=100/160000, loss=1.4862, lr=0.009994, batch_cost=0.8316, reader_cost=0.20784, ips=4.8101 samples/sec | ETA 36:56:09\n",
      "2021-11-19 23:34:39 [INFO]\t[TRAIN] epoch=1, iter=110/160000, loss=1.4489, lr=0.009994, batch_cost=0.7935, reader_cost=0.17254, ips=5.0411 samples/sec | ETA 35:14:29\n",
      "2021-11-19 23:34:47 [INFO]\t[TRAIN] epoch=1, iter=120/160000, loss=1.4579, lr=0.009993, batch_cost=0.7863, reader_cost=0.16446, ips=5.0871 samples/sec | ETA 34:55:13\n",
      "2021-11-19 23:34:55 [INFO]\t[TRAIN] epoch=1, iter=130/160000, loss=1.4878, lr=0.009993, batch_cost=0.7963, reader_cost=0.17314, ips=5.0234 samples/sec | ETA 35:21:39\n",
      "2021-11-19 23:35:03 [INFO]\t[TRAIN] epoch=1, iter=140/160000, loss=1.3636, lr=0.009992, batch_cost=0.7955, reader_cost=0.17413, ips=5.0285 samples/sec | ETA 35:19:24\n",
      "2021-11-19 23:35:11 [INFO]\t[TRAIN] epoch=1, iter=150/160000, loss=1.3544, lr=0.009992, batch_cost=0.8038, reader_cost=0.17772, ips=4.9767 samples/sec | ETA 35:41:19\n",
      "2021-11-19 23:35:19 [INFO]\t[TRAIN] epoch=1, iter=160/160000, loss=1.3667, lr=0.009991, batch_cost=0.7964, reader_cost=0.17264, ips=5.0228 samples/sec | ETA 35:21:31\n",
      "2021-11-19 23:35:27 [INFO]\t[TRAIN] epoch=1, iter=170/160000, loss=1.4676, lr=0.009990, batch_cost=0.8000, reader_cost=0.17174, ips=5.0002 samples/sec | ETA 35:30:57\n",
      "2021-11-19 23:35:35 [INFO]\t[TRAIN] epoch=1, iter=180/160000, loss=1.3288, lr=0.009990, batch_cost=0.8073, reader_cost=0.17673, ips=4.9545 samples/sec | ETA 35:50:29\n",
      "2021-11-19 23:35:43 [INFO]\t[TRAIN] epoch=1, iter=190/160000, loss=1.2694, lr=0.009989, batch_cost=0.8109, reader_cost=0.17932, ips=4.9326 samples/sec | ETA 35:59:54\n",
      "2021-11-19 23:35:52 [INFO]\t[TRAIN] epoch=1, iter=200/160000, loss=1.7412, lr=0.009989, batch_cost=0.8270, reader_cost=0.19189, ips=4.8368 samples/sec | ETA 36:42:32\n",
      "2021-11-19 23:36:00 [INFO]\t[TRAIN] epoch=1, iter=210/160000, loss=1.3714, lr=0.009988, batch_cost=0.7941, reader_cost=0.15279, ips=5.0373 samples/sec | ETA 35:14:45\n",
      "2021-11-19 23:36:08 [INFO]\t[TRAIN] epoch=1, iter=220/160000, loss=1.2282, lr=0.009988, batch_cost=0.8119, reader_cost=0.17822, ips=4.9265 samples/sec | ETA 36:02:09\n",
      "2021-11-19 23:36:16 [INFO]\t[TRAIN] epoch=1, iter=230/160000, loss=1.1856, lr=0.009987, batch_cost=0.8093, reader_cost=0.17204, ips=4.9423 samples/sec | ETA 35:55:07\n",
      "2021-11-19 23:36:24 [INFO]\t[TRAIN] epoch=1, iter=240/160000, loss=1.3203, lr=0.009987, batch_cost=0.8129, reader_cost=0.17533, ips=4.9205 samples/sec | ETA 36:04:33\n",
      "2021-11-19 23:36:32 [INFO]\t[TRAIN] epoch=1, iter=250/160000, loss=1.2888, lr=0.009986, batch_cost=0.8220, reader_cost=0.18191, ips=4.8662 samples/sec | ETA 36:28:34\n",
      "2021-11-19 23:36:40 [INFO]\t[TRAIN] epoch=1, iter=260/160000, loss=1.3587, lr=0.009985, batch_cost=0.8089, reader_cost=0.17374, ips=4.9448 samples/sec | ETA 35:53:39\n",
      "2021-11-19 23:36:48 [INFO]\t[TRAIN] epoch=1, iter=270/160000, loss=1.3926, lr=0.009985, batch_cost=0.8222, reader_cost=0.18550, ips=4.8650 samples/sec | ETA 36:28:50\n",
      "2021-11-19 23:36:56 [INFO]\t[TRAIN] epoch=1, iter=280/160000, loss=1.4160, lr=0.009984, batch_cost=0.7914, reader_cost=0.15538, ips=5.0544 samples/sec | ETA 35:06:39\n",
      "2021-11-19 23:37:05 [INFO]\t[TRAIN] epoch=1, iter=290/160000, loss=1.2371, lr=0.009984, batch_cost=0.8174, reader_cost=0.18461, ips=4.8935 samples/sec | ETA 36:15:49\n",
      "2021-11-19 23:37:13 [INFO]\t[TRAIN] epoch=1, iter=300/160000, loss=1.3900, lr=0.009983, batch_cost=0.8258, reader_cost=0.19288, ips=4.8438 samples/sec | ETA 36:37:58\n",
      "2021-11-19 23:37:21 [INFO]\t[TRAIN] epoch=1, iter=310/160000, loss=1.2813, lr=0.009983, batch_cost=0.8209, reader_cost=0.18521, ips=4.8727 samples/sec | ETA 36:24:50\n",
      "2021-11-19 23:37:29 [INFO]\t[TRAIN] epoch=1, iter=320/160000, loss=1.5827, lr=0.009982, batch_cost=0.8219, reader_cost=0.18640, ips=4.8668 samples/sec | ETA 36:27:21\n",
      "2021-11-19 23:37:37 [INFO]\t[TRAIN] epoch=1, iter=330/160000, loss=1.2394, lr=0.009981, batch_cost=0.8037, reader_cost=0.16785, ips=4.9773 samples/sec | ETA 35:38:38\n",
      "2021-11-19 23:37:45 [INFO]\t[TRAIN] epoch=1, iter=340/160000, loss=1.3835, lr=0.009981, batch_cost=0.8165, reader_cost=0.18102, ips=4.8989 samples/sec | ETA 36:12:45\n",
      "2021-11-19 23:37:53 [INFO]\t[TRAIN] epoch=1, iter=350/160000, loss=1.1512, lr=0.009980, batch_cost=0.7882, reader_cost=0.15279, ips=5.0749 samples/sec | ETA 34:57:14\n",
      "2021-11-19 23:38:02 [INFO]\t[TRAIN] epoch=1, iter=360/160000, loss=1.6114, lr=0.009980, batch_cost=0.8155, reader_cost=0.18122, ips=4.9049 samples/sec | ETA 36:09:49\n",
      "2021-11-19 23:38:10 [INFO]\t[TRAIN] epoch=1, iter=370/160000, loss=1.3693, lr=0.009979, batch_cost=0.7986, reader_cost=0.16117, ips=5.0090 samples/sec | ETA 35:24:34\n",
      "2021-11-19 23:38:18 [INFO]\t[TRAIN] epoch=1, iter=380/160000, loss=1.5006, lr=0.009979, batch_cost=0.8397, reader_cost=0.20176, ips=4.7639 samples/sec | ETA 37:13:45\n",
      "2021-11-19 23:38:26 [INFO]\t[TRAIN] epoch=1, iter=390/160000, loss=1.2726, lr=0.009978, batch_cost=0.8147, reader_cost=0.17713, ips=4.9097 samples/sec | ETA 36:07:17\n",
      "2021-11-19 23:38:34 [INFO]\t[TRAIN] epoch=1, iter=400/160000, loss=1.4261, lr=0.009978, batch_cost=0.8255, reader_cost=0.19189, ips=4.8456 samples/sec | ETA 36:35:48\n",
      "2021-11-19 23:38:42 [INFO]\t[TRAIN] epoch=1, iter=410/160000, loss=1.2582, lr=0.009977, batch_cost=0.8133, reader_cost=0.17703, ips=4.9181 samples/sec | ETA 36:03:18\n",
      "2021-11-19 23:38:51 [INFO]\t[TRAIN] epoch=1, iter=420/160000, loss=1.1271, lr=0.009976, batch_cost=0.8318, reader_cost=0.19618, ips=4.8090 samples/sec | ETA 36:52:14\n",
      "2021-11-19 23:38:59 [INFO]\t[TRAIN] epoch=1, iter=430/160000, loss=1.2045, lr=0.009976, batch_cost=0.7997, reader_cost=0.16336, ips=5.0021 samples/sec | ETA 35:26:41\n",
      "2021-11-19 23:39:07 [INFO]\t[TRAIN] epoch=1, iter=440/160000, loss=1.3335, lr=0.009975, batch_cost=0.8218, reader_cost=0.18700, ips=4.8674 samples/sec | ETA 36:25:26\n",
      "2021-11-19 23:39:15 [INFO]\t[TRAIN] epoch=1, iter=450/160000, loss=1.2170, lr=0.009975, batch_cost=0.8027, reader_cost=0.16197, ips=4.9835 samples/sec | ETA 35:34:23\n",
      "2021-11-19 23:39:23 [INFO]\t[TRAIN] epoch=1, iter=460/160000, loss=1.5345, lr=0.009974, batch_cost=0.8160, reader_cost=0.18032, ips=4.9019 samples/sec | ETA 36:09:47\n",
      "2021-11-19 23:39:32 [INFO]\t[TRAIN] epoch=1, iter=470/160000, loss=1.1915, lr=0.009974, batch_cost=0.8388, reader_cost=0.20016, ips=4.7690 samples/sec | ETA 37:10:06\n",
      "2021-11-19 23:39:40 [INFO]\t[TRAIN] epoch=1, iter=480/160000, loss=1.3346, lr=0.009973, batch_cost=0.7996, reader_cost=0.16067, ips=5.0027 samples/sec | ETA 35:25:46\n",
      "2021-11-19 23:39:48 [INFO]\t[TRAIN] epoch=1, iter=490/160000, loss=1.3373, lr=0.009972, batch_cost=0.8405, reader_cost=0.20465, ips=4.7593 samples/sec | ETA 37:14:20\n",
      "2021-11-19 23:39:56 [INFO]\t[TRAIN] epoch=1, iter=500/160000, loss=1.1867, lr=0.009972, batch_cost=0.8088, reader_cost=0.17334, ips=4.9454 samples/sec | ETA 35:50:09\n",
      "2021-11-19 23:40:04 [INFO]\t[TRAIN] epoch=1, iter=510/160000, loss=1.1825, lr=0.009971, batch_cost=0.8189, reader_cost=0.18181, ips=4.8845 samples/sec | ETA 36:16:47\n",
      "2021-11-19 23:40:13 [INFO]\t[TRAIN] epoch=1, iter=520/160000, loss=1.3008, lr=0.009971, batch_cost=0.8267, reader_cost=0.19079, ips=4.8386 samples/sec | ETA 36:37:20\n",
      "2021-11-19 23:40:20 [INFO]\t[TRAIN] epoch=1, iter=530/160000, loss=1.2705, lr=0.009970, batch_cost=0.7941, reader_cost=0.15509, ips=5.0373 samples/sec | ETA 35:10:31\n",
      "2021-11-19 23:40:29 [INFO]\t[TRAIN] epoch=1, iter=540/160000, loss=1.2206, lr=0.009970, batch_cost=0.8128, reader_cost=0.17244, ips=4.9211 samples/sec | ETA 36:00:13\n",
      "2021-11-19 23:40:37 [INFO]\t[TRAIN] epoch=1, iter=550/160000, loss=1.2026, lr=0.009969, batch_cost=0.8235, reader_cost=0.18451, ips=4.8573 samples/sec | ETA 36:28:26\n",
      "2021-11-19 23:40:45 [INFO]\t[TRAIN] epoch=1, iter=560/160000, loss=1.1804, lr=0.009969, batch_cost=0.8204, reader_cost=0.18361, ips=4.8756 samples/sec | ETA 36:20:05\n",
      "2021-11-19 23:40:53 [INFO]\t[TRAIN] epoch=1, iter=570/160000, loss=1.2970, lr=0.009968, batch_cost=0.8366, reader_cost=0.20016, ips=4.7815 samples/sec | ETA 37:02:53\n",
      "2021-11-19 23:41:02 [INFO]\t[TRAIN] epoch=1, iter=580/160000, loss=1.1211, lr=0.009967, batch_cost=0.8150, reader_cost=0.17802, ips=4.9079 samples/sec | ETA 36:05:30\n",
      "2021-11-19 23:41:10 [INFO]\t[TRAIN] epoch=1, iter=590/160000, loss=1.2989, lr=0.009967, batch_cost=0.8243, reader_cost=0.18700, ips=4.8526 samples/sec | ETA 36:30:00\n",
      "2021-11-19 23:41:18 [INFO]\t[TRAIN] epoch=1, iter=600/160000, loss=1.0284, lr=0.009966, batch_cost=0.7768, reader_cost=0.13953, ips=5.1492 samples/sec | ETA 34:23:45\n",
      "2021-11-19 23:41:26 [INFO]\t[TRAIN] epoch=1, iter=610/160000, loss=1.2912, lr=0.009966, batch_cost=0.7994, reader_cost=0.16127, ips=5.0040 samples/sec | ETA 35:23:30\n",
      "2021-11-19 23:41:34 [INFO]\t[TRAIN] epoch=1, iter=620/160000, loss=1.1634, lr=0.009965, batch_cost=0.8095, reader_cost=0.16995, ips=4.9411 samples/sec | ETA 35:50:23\n",
      "2021-11-19 23:41:42 [INFO]\t[TRAIN] epoch=1, iter=630/160000, loss=1.2412, lr=0.009965, batch_cost=0.8180, reader_cost=0.17703, ips=4.8899 samples/sec | ETA 36:12:46\n",
      "2021-11-19 23:41:50 [INFO]\t[TRAIN] epoch=1, iter=640/160000, loss=1.1670, lr=0.009964, batch_cost=0.8380, reader_cost=0.20086, ips=4.7735 samples/sec | ETA 37:05:37\n",
      "2021-11-19 23:41:58 [INFO]\t[TRAIN] epoch=1, iter=650/160000, loss=1.2228, lr=0.009963, batch_cost=0.8300, reader_cost=0.18750, ips=4.8194 samples/sec | ETA 36:44:17\n",
      "2021-11-19 23:42:07 [INFO]\t[TRAIN] epoch=1, iter=660/160000, loss=1.0531, lr=0.009963, batch_cost=0.8153, reader_cost=0.17533, ips=4.9061 samples/sec | ETA 36:05:13\n",
      "2021-11-19 23:42:15 [INFO]\t[TRAIN] epoch=1, iter=670/160000, loss=1.2772, lr=0.009962, batch_cost=0.8181, reader_cost=0.16905, ips=4.8893 samples/sec | ETA 36:12:29\n",
      "2021-11-19 23:42:23 [INFO]\t[TRAIN] epoch=1, iter=680/160000, loss=1.2572, lr=0.009962, batch_cost=0.8197, reader_cost=0.17872, ips=4.8798 samples/sec | ETA 36:16:35\n",
      "2021-11-19 23:42:31 [INFO]\t[TRAIN] epoch=1, iter=690/160000, loss=1.3429, lr=0.009961, batch_cost=0.8391, reader_cost=0.19548, ips=4.7673 samples/sec | ETA 37:07:50\n",
      "2021-11-19 23:42:40 [INFO]\t[TRAIN] epoch=1, iter=700/160000, loss=1.1406, lr=0.009961, batch_cost=0.8436, reader_cost=0.20106, ips=4.7413 samples/sec | ETA 37:19:52\n",
      "2021-11-19 23:42:48 [INFO]\t[TRAIN] epoch=1, iter=710/160000, loss=1.1263, lr=0.009960, batch_cost=0.8439, reader_cost=0.19448, ips=4.7397 samples/sec | ETA 37:20:31\n",
      "2021-11-19 23:42:56 [INFO]\t[TRAIN] epoch=1, iter=720/160000, loss=1.1030, lr=0.009960, batch_cost=0.7890, reader_cost=0.15020, ips=5.0698 samples/sec | ETA 34:54:30\n",
      "2021-11-19 23:43:04 [INFO]\t[TRAIN] epoch=1, iter=730/160000, loss=0.9862, lr=0.009959, batch_cost=0.8000, reader_cost=0.16446, ips=5.0002 samples/sec | ETA 35:23:29\n",
      "2021-11-19 23:43:12 [INFO]\t[TRAIN] epoch=1, iter=740/160000, loss=1.1290, lr=0.009958, batch_cost=0.7951, reader_cost=0.15838, ips=5.0310 samples/sec | ETA 35:10:23\n"
     ]
    }
   ],
   "source": [
    "%run train.py --config configs/unet/unet_cityscapes_1024x512_160k.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-23 21:04:19 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 2\n",
      "iters: 160000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.05\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "model:\n",
      "  pretrained: null\n",
      "  type: AttentionUNet\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/voc/VOCdevkit/VOCleather/\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: data/voc/VOCdevkit/VOCleather/train04.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: data/voc/VOCdevkit/VOCleather/\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: data/voc/VOCdevkit/VOCleather/val04.txt\n",
      "------------------------------------------------\n",
      "2021-11-23 21:04:19 [INFO]\tNumber of predict images = 25\n",
      "2021-11-23 21:04:19 [INFO]\tLoading pretrained model from output_attention_unet_vocleather_512x512_280_202111232009/best_model/model.pdparams\n",
      "2021-11-23 21:04:20 [INFO]\tThere are 206/206 variables loaded into AttentionUNet.\n",
      "2021-11-23 21:04:20 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 9s 376ms/step\n"
     ]
    }
   ],
   "source": [
    "#d:\n",
    "#cd Deep_Learning\\liangyy\\PaddleSeg\n",
    "#conda activate paddlepaddle\n",
    "#python train.py --config configs\\unet\\unet_pascalvoc_1024x512_160k.yml --use_vdl --save_interval 500 --resume_model output/iter_10000\n",
    "\n",
    "#%run tools/split_dataset_list.py data/voc/VOCdevkit/VOCleather JPEGImages02 SegmentationClass02 --split 0.7 0.1 0.2 --format bmp png\n",
    "#%run tools/split_dataset_list.py data/voc/VOCdevkit/VOCleather JPEGImages04 SegmentationClass04 --split 0.7 0.1 0.2 --format bmp png\n",
    "\n",
    "#%run tools/labelme2seg.py data/voc/VOCdevkit/VOCleather/JPEGImages02\n",
    "#%run tools/labelme2seg.py data/voc/VOCdevkit/VOCleather/JPEGImages04\n",
    "\n",
    "#python train.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --do_eval --use_vdl --save_interval 500 --save_dir output_unet_pascalvoc_1024x512_160k --resume_model output_unet_pascalvoc_1024x512_160k/iter_500\n",
    "#python train.py --config configs/unet/unet_vocleather_512x512_280.yml --do_eval --use_vdl --save_interval 500 --save_dir output_unet_vocleather_512x512_280 --resume_model output_unet_vocleather_512x512_280/iter_500\n",
    "#python train.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --do_eval --use_vdl --save_interval 500 --save_dir output_attention_unet_vocleather_512x512_280 --resume_model output_attention_unet_vocleather_512x512_280/iter_1500\n",
    "#python train.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --do_eval --use_vdl --save_interval 500 --save_dir output_attention_unet_vocleather_512x512_280_202111232009 --resume_model output_attention_unet_vocleather_512x512_280_202111232009/iter_50\n",
    "\n",
    "#visualdl --logdir output_unet_pascalvoc_1024x512_160k/\n",
    "#visualdl --logdir D:\\Deep_Learning\\liangyy\\PaddleSeg\\output_attention_unet_vocleather_512x512_280_202111232009\n",
    "\n",
    "#python val.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --model_path output_unet_pascalvoc_1024x512_160k/iter_1500/model.pdparams\n",
    "\n",
    "#%run predict.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --model_path output_unet_pascalvoc_1024x512_160k/iter_2000/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test --save_dir output_unet_pascalvoc_1024x512_160k/result\n",
    "#%run predict.py --config configs/unet/unet_vocleather_512x512_280.yml --model_path output_unet_vocleather_512x512_280/iter_300/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test --save_dir output_unet_vocleather_512x512_280/result\n",
    "#%run predict.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --model_path output_attention_unet_vocleather_512x512_280/best_model/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test --save_dir output_attention_unet_vocleather_512x512_280/result\n",
    "#%run predict.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --model_path output/best_model/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test --save_dir output/result\n",
    "%run predict.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --model_path output_attention_unet_vocleather_512x512_280_202111232009/best_model/model.pdparams --image_path data/voc/VOCdevkit/VOCleather/test04 --save_dir output_attention_unet_vocleather_512x512_280_202111232009/result\n",
    "\n",
    "#python export.py --config configs/unet/unet_pascalvoc_1024x512_160k.yml --model_path output_unet_pascalvoc_1024x512_160k/iter_10000/model.pdparams --save_dir output_unet_pascalvoc_1024x512_160k\n",
    "#python export.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --model_path output_unet_pascalvoc_1024x512_160k/best_model/model.pdparams --save_dir output_attention_unet_vocleather_512x512_280\n",
    "#python export.py --config configs/unet/attention_unet_vocleather_512x512_280.yml --model_path output/best_model/model.pdparams --save_dir output\n",
    "\n",
    "#python deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output_attention_unet_vocleather_512x512_280/deploy.yaml --image_path data/voc/VOCdevkit/VOCleather/test/Image_20211105141003930.bmp --save_dir output_attention_unet_vocleather_512x512_280\n",
    "#python deploy/python/infer.py --config output_attention_unet_vocleather_512x512_280/deploy.yaml --image_path data/voc/VOCdevkit/VOCleather/test/Image_20211105141003930.bmp --save_dir output_attention_unet_vocleather_512x512_280\n",
    "#python deploy/python/infer.py --device cpu --cpu_threads 2 --enable_mkldnn False --config output/deploy.yaml --image_path data/voc/VOCdevkit/VOCleather/test/Image_20211105141003930.bmp --save_dir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件名为:  D:\\Deep_Learning\\liangyy\\data\\voc\\VOCdevkit\\VOCleather\\test04.txt\n",
      "读取的数据为: 孔洞003.bmp\n",
      "读取的数据为: 烂点008.bmp\n",
      "读取的数据为: 牙签烂点002.bmp\n",
      "读取的数据为: 牙签007.bmp\n",
      "读取的数据为: 生长纹007.bmp\n",
      "读取的数据为: 烂点021.bmp\n",
      "读取的数据为: 沙孔002.bmp\n",
      "读取的数据为: 烂点002.bmp\n",
      "读取的数据为: 压印001.bmp\n",
      "读取的数据为: 生长纹004.bmp\n",
      "读取的数据为: 折痕017.bmp\n",
      "读取的数据为: 牙签006.bmp\n",
      "读取的数据为: 折痕016.bmp\n",
      "读取的数据为: 生长纹烂点005.bmp\n",
      "读取的数据为: 折痕008.bmp\n",
      "读取的数据为: 疤点013.bmp\n",
      "读取的数据为: 标记002.bmp\n",
      "读取的数据为: 疤点005.bmp\n",
      "读取的数据为: 折痕010.bmp\n",
      "读取的数据为: 折痕夹子印.bmp\n",
      "读取的数据为: 疤点002.bmp\n",
      "读取的数据为: 折痕005.bmp\n",
      "读取的数据为: 烂点028.bmp\n",
      "读取的数据为: 牙签010.bmp\n",
      "读取的数据为: 烂点011.bmp\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "import os\n",
    "\n",
    "pwd = 'D:\\\\Deep_Learning\\\\liangyy\\\\data\\\\voc\\\\VOCdevkit\\\\VOCleather'          #<--------------------------------\n",
    "# 打开文件\n",
    "fo = open(pwd+\"\\\\\"+\"test04.txt\", \"r\", encoding='gbk')                         #<--------------------------------\n",
    "print(\"文件名为: \", fo.name)\n",
    " \n",
    "for line in fo.readlines():                          #依次读取每行  \n",
    "    line = line.strip().split()[0].split('\\\\')[1]    #去掉每行头尾空白         #<--------------------------------\n",
    "    print(\"读取的数据为: %s\" % line)\n",
    "    \n",
    "    os.system('copy %s\\\\JPEGImages04\\\\%s %s\\\\test04\\\\%s' % (pwd,line,pwd,line)) #<--------------------------------\n",
    " \n",
    "# 关闭文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "trainval_percent = 0.9\n",
    "train_percent = 0.9\n",
    "xmlfilepath = '../SegmentationClass02'#<--------------------------\n",
    "txtsavepath = '../ImageSets/Main'\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    "\n",
    "num = len(total_xml)\n",
    "list = range(num)\n",
    "tv = int(num*trainval_percent)\n",
    "tr = int(tv*train_percent)\n",
    "trainval = random.sample(list, tv)\n",
    "train = random.sample(trainval, tr)\n",
    "\n",
    "ftrainval = open('../ImageSets/Main/trainval.txt', 'w', encoding='utf-8')\n",
    "ftest = open('../ImageSets/Main/test.txt', 'w', encoding='utf-8')\n",
    "ftrain = open('../ImageSets/Main/train.txt', 'w', encoding='utf-8')\n",
    "fval = open('../ImageSets/Main/val.txt', 'w', encoding='utf-8')\n",
    "\n",
    "for i in list:\n",
    "    name = total_xml[i][:-4]+'\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    "\n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest .close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "sets = [('', 'train'), ('', 'val'), ('', 'test')]\n",
    "\n",
    "wd = '.'\n",
    "\n",
    "for year, image_set in sets:\n",
    "    image_ids = open('../ImageSets/Main/%s.txt' % image_set, encoding='utf-8').read().strip().split()\n",
    "    list_file = open('../%s.txt' % image_set, 'w', encoding='utf-8')\n",
    "    for image_id in image_ids:\n",
    "        #list_file.write('%s/JPEGImages01/%s.%s\\n' % (wd, image_id, 'bmp'))#<--------------------------\n",
    "        list_file.write('%s/JPEGImages02/%s.%s %s/SegmentationClass02/%s.%s\\n' % (wd, image_id, 'bmp', wd, image_id, 'png'))#<--------------------------\n",
    "    list_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取目录下所有图片,更改尺寸后保存到另一目录\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "def convertjpg(jpgfile,outdir,width=512,height=512):\n",
    "    img=Image.open(jpgfile)\n",
    "    try:\n",
    "        new_img=img.resize((width,height),Image.BILINEAR)   \n",
    "        new_img.save(os.path.join(outdir,os.path.basename(jpgfile)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "for jpgfile in glob.glob(\"D:\\\\Deep_Learning\\\\liangyy\\\\data\\\\voc\\\\VOCdevkit\\\\VOCleather\\\\JPEGImages02\\\\*.bmp\"):\n",
    "    convertjpg(jpgfile,\"D:\\\\Deep_Learning\\\\liangyy\\\\data\\\\voc\\\\VOCdevkit\\\\VOCleather\\\\JPEGImages021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddlepaddle",
   "language": "python",
   "name": "paddlepaddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
